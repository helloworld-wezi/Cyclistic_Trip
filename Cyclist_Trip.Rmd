---
title: "Cyclistic: How Does a Bike-Share Navigate Speedy Success"
output:
  html_document:
    df_print: paged
---

# Project Cyclistic

This Notebook is a summary of my thought process in solving a business task as a requirement to Google Data Analytics Capstone Course.

## Step 1: ASK

Identification of Business Task(s) using the following guideline:

(1) How do annual members and casual riders use Cyclistic bikes differently?
(2) Why would casual riders buy Cyclistic annual memberships?
(3) How can Cyclistic use digital media to inï¬‚uence casual riders to become members?

Identification of Stakeholder(s):

(1) Lily Moreno, the director of marketing and (supposedly) my manager, who is responsible for the development of campaigns and initiatives to promote bike-sharing program.
(2) Cyclistic marketing analytics team, who are responsible for collecting, analyzing, and reporting data that helps guide the Cyclistic marketing strategy.
(3) Cyclistic executive team, who will decide whether to approve the recommended marketing program.

Identification of the objective(s):

(1) Moreno believes that maximizing the number of annual members will be key to future growth. Therefore, converting casual riders into annual members is the priority here.
(2) The data analyst should design marketing strategies aimed at converting casual riders into annual members, preferably using the digital media.


## Step 2: PREPARE

### Load the Packages needed in R for data analysis purpose

For this project, I use tidyverse, janitor, and lubridate package. Tidyverse is a common package used for data analysis puspose, just as janitor is, while lubridate is a package used to work with date more easily.

```{r load_package}
library(tidyverse)
library(janitor)
library(lubridate)
```

### The credibility of the data

For this project the task is to analyze the last 12 months of bike ride data in Chicago, but since during the last 12 months the environment is heavily affected by COVID-19 pandemic, I decided to add 12 more months of data into the analysis to make sure I won't leave anything out. Furthermore, I'm also curious about the difference in bike ride before and during/after the pandemic. I downloaded the data from [here](https://divvy-tripdata.s3.amazonaws.com/index.html). From the site, it can be asserted that the data is credible although there are some important variables that I feel are needed for the scope of the project. However, using only the data from the site is probably good enough to get a conclusion to guide the analytic team.

### Preparing the data

#### Importing the Data

I imported the csv data and put them into R dataframes.

```{r import_data}
trip_2019q3 <- read.csv(
  "Divvy_Trips_2019_Q3.csv"
)

trip_2019q4 <- read.csv(
  "Divvy_Trips_2019_Q4.csv"
)

trip_2020q1 <- read.csv(
  "Divvy_Trips_2020_Q1.csv"
)

trip_202004 <- read.csv(
  "202004-divvy-tripdata.csv"
)

trip_202005 <- read.csv(
  "202005-divvy-tripdata.csv"
)

trip_202006 <- read.csv(
  "202006-divvy-tripdata.csv"
)

trip_202007 <- read.csv(
  "202007-divvy-tripdata.csv"
)

trip_202008 <- read.csv(
  "202008-divvy-tripdata.csv"
)

trip_202009 <- read.csv(
  "202009-divvy-tripdata.csv"
)

trip_202010 <- read.csv(
  "202010-divvy-tripdata.csv"
)

trip_202011 <- read.csv(
  "202011-divvy-tripdata.csv"
)

trip_202012 <- read.csv(
  "202012-divvy-tripdata.csv"
)

trip_202101 <- read.csv(
  "202101-divvy-tripdata.csv"
)

trip_202102 <- read.csv(
  "202102-divvy-tripdata.csv"
)

trip_202103 <- read.csv(
  "202103-divvy-tripdata.csv"
)

trip_202104 <- read.csv(
  "202104-divvy-tripdata.csv"
)

trip_202105 <- read.csv(
  "202105-divvy-tripdata.csv"
)

trip_202106 <- read.csv(
  "202106-divvy-tripdata.csv"
)
```

Now, to make sure that all the dataframes are of the same structure, I use a function to check if the column names are all the same. I use the function from [here](https://stackoverflow.com/questions/26566251/how-to-check-if-a-two-data-frame-have-the-same-column-names).

```{r col_name_function}
col_names_checkers <- function(x, y){
  for (i in names(x)) {
    if (!(i %in% names(y))){
      print('Warning: names are not the same')
      break
    }
    else if (i == tail(names(y), n = 1)){
      print('All names are identical')
    }
  }
}
```

I then use the above function for dataframes in pairs.

```{r check_column_names}
col_names_checkers(trip_2019q3, trip_2019q4)
col_names_checkers(trip_2019q4, trip_2020q1)
col_names_checkers(trip_2020q1, trip_202004)
col_names_checkers(trip_202004, trip_202005)
col_names_checkers(trip_202005, trip_202006)
col_names_checkers(trip_202006, trip_202007)
col_names_checkers(trip_202007, trip_202008)
col_names_checkers(trip_202008, trip_202009)
col_names_checkers(trip_202009, trip_202010)
col_names_checkers(trip_202010, trip_202011)
col_names_checkers(trip_202011, trip_202012)
col_names_checkers(trip_202012, trip_202101)
col_names_checkers(trip_202101, trip_202102)
col_names_checkers(trip_202102, trip_202103)
col_names_checkers(trip_202103, trip_202104)
col_names_checkers(trip_202104, trip_202105)
col_names_checkers(trip_202105, trip_202106)
```
#### Data Structure

From the result above, it seems that the column names are different between the data before 2020 and during 2020 onwards. Therefore, I check the structure of the table in 2019 data and compared it with that in 2020.

```{r structure_of_2019_data}
str(trip_2019q4)
```

```{r structure_of_2020_data}
str(trip_2020q1)
```

#### Organize the Data

I use the structure in 2020 onwards as the pivot and change the column names of the 2019 data.

```{r change_column_names_2019}
trip_2019q3_2 <- rename(trip_2019q3,
                        ride_id = trip_id,
                        rideable_type = bikeid,
                        started_at = start_time,
                        ended_at = end_time,
                        start_station_name = from_station_name,
                        start_station_id = from_station_id,
                        end_station_name = to_station_name,
                        end_station_id = to_station_id,
                        member_casual = usertype
)

trip_2019q4_2 <- rename(trip_2019q4,
                        ride_id = trip_id,
                        rideable_type = bikeid,
                        started_at = start_time,
                        ended_at = end_time,
                        start_station_name = from_station_name,
                        start_station_id = from_station_id,
                        end_station_name = to_station_name,
                        end_station_id = to_station_id,
                        member_casual = usertype
)
```

Then I want to check the structure of all dataframes simultaneously using codes from [here](https://stackoverflow.com/questions/53264993/comparing-column-names-in-r-across-various-data-frames).

First, I create a list of dataframes.

```{r create_function_check_dataframe_simultaneous}
all_trip <- list(
  trip_2019q3_2,
  trip_2019q4_2,
  trip_2020q1,
  trip_202004,
  trip_202005,
  trip_202006,
  trip_202007,
  trip_202008,
  trip_202009,
  trip_202010,
  trip_202011,
  trip_202012,
  trip_202101,
  trip_202102,
  trip_202103,
  trip_202104,
  trip_202105,
  trip_202106
)
```

Second, I use the following function:

```{r compare_columns}
compare_df_cols(all_trip)
```

Apparently there are two columns with different data types. Also there are some columns that exist in 2019 data but do not exist in 2020 data. The opposite is also true. Thus I focus on the columns/variables that exist in all data frames. 

I check the structure of data frames with different data types:
```{r check_structure_1}
str(trip_2020q1)
```

```{r check_sructure_2}
str(trip_202106)
```

I use the following codes to change the table structure of dataframes:

```{r manipulate_all_dataframes}
trip_2019q3_3 <- mutate(trip_2019q3_2,
                        ride_id = as.character(as.integer(ride_id)),
                        start_station_id = as.character(as.integer(start_station_id)),
                        end_station_id = as.character(as.integer(end_station_id)),
                        rideable_type = as.character(as.integer(rideable_type)))
trip_2019q4_3 <- mutate(trip_2019q4_2,
                        ride_id = as.character(as.integer(ride_id)),
                        start_station_id = as.character(as.integer(start_station_id)),
                        end_station_id = as.character(as.integer(end_station_id)),
                        rideable_type = as.character(as.integer(rideable_type)))
trip_2020q1_2 <- mutate(trip_2020q1,
                        start_station_id = as.character(as.integer(start_station_id)),
                        end_station_id = as.character(as.integer(end_station_id)))
trip_202004_2 <- mutate(trip_202004,
                        start_station_id = as.character(as.integer(start_station_id)),
                        end_station_id = as.character(as.integer(end_station_id)))
trip_202005_2 <- mutate(trip_202005,
                        start_station_id = as.character(as.integer(start_station_id)),
                        end_station_id = as.character(as.integer(end_station_id)))
trip_202006_2 <- mutate(trip_202006,
                        start_station_id = as.character(as.integer(start_station_id)),
                        end_station_id = as.character(as.integer(end_station_id)))
trip_202007_2 <- mutate(trip_202007,
                        start_station_id = as.character(as.integer(start_station_id)),
                        end_station_id = as.character(as.integer(end_station_id)))
trip_202008_2 <- mutate(trip_202008,
                        start_station_id = as.character(as.integer(start_station_id)),
                        end_station_id = as.character(as.integer(end_station_id)))
trip_202009_2 <- mutate(trip_202009,
                        start_station_id = as.character(as.integer(start_station_id)),
                        end_station_id = as.character(as.integer(end_station_id)))
trip_202010_2 <- mutate(trip_202010,
                        start_station_id = as.character(as.integer(start_station_id)),
                        end_station_id = as.character(as.integer(end_station_id)))
trip_202011_2 <- mutate(trip_202011,
                        start_station_id = as.character(as.integer(start_station_id)),
                        end_station_id = as.character(as.integer(end_station_id)))
```

#### Checking for Inconsistencies

Then I check again for any inconsistencies among the dataframes. First, I create a second list.

```{r create_second_list}
all_trip_2 <- list(
  trip_2019q3_3,
  trip_2019q4_3,
  trip_2020q1_2,
  trip_202008_2,
  trip_202009_2,
  trip_202010_2,
  trip_202011_2,
  trip_202012,
  trip_202101,
  trip_202102,
  trip_202103,
  trip_202104,
  trip_202105,
  trip_202106
)
```

Second, I use the same function as above.

```{r compare_columns_2}
compare_df_cols(all_trip_2)
```
For now I ignore the columns that exist in only some of dataframes. It will be dealt later in the PROCESS step.

## Step 2 and 3: PROCESS AND ANALYZE

### Cleaning and Organizing the Data

#### Checking missing values

I'm curious about whether the values in the table are complete, which means there is no missing values or blank. I use the following function that I got from [here](https://stackoverflow.com/questions/8317231/elegant-way-to-report-missing-values-in-a-data-frame).

```{r create_function_is_missing}
is_missing <- function(x){
  missing_strs <- c('', 'null', 'na', 'nan', 'inf', '-inf', '-9', 'unknown', 'missing')
  ifelse((is.na(x) | is.nan(x) | is.infinite(x)), TRUE,
         ifelse(trimws(tolower(x)) %in% missing_strs, TRUE, FALSE))
}
```

Then I check for missing values in a dataframe, say, trip_202004.

```{r check_for_missing_values_1}
summarize_all(trip_202004, ~sum(is_missing(.)))
```

There are some missing values. So I check for other dataframes as well.

```{r check_for_missing_values_2}
summarize_all(trip_202106, ~sum(is_missing(.) / nrow(trip_202106)))
summarize_all(trip_202105, ~sum(is_missing(.) / nrow(trip_202105)))
summarize_all(trip_202104, ~sum(is_missing(.) / nrow(trip_202104)))
summarize_all(trip_202103, ~sum(is_missing(.) / nrow(trip_202103)))
summarize_all(trip_202102, ~sum(is_missing(.) / nrow(trip_202102)))
summarize_all(trip_202101, ~sum(is_missing(.) / nrow(trip_202101)))
summarize_all(trip_202012, ~sum(is_missing(.) / nrow(trip_202012)))
summarize_all(trip_202011, ~sum(is_missing(.) / nrow(trip_202011)))
summarize_all(trip_202010, ~sum(is_missing(.) / nrow(trip_202010)))
summarize_all(trip_202009, ~sum(is_missing(.) / nrow(trip_202009)))
summarize_all(trip_202008, ~sum(is_missing(.) / nrow(trip_202008)))
summarize_all(trip_202007, ~sum(is_missing(.) / nrow(trip_202007)))
summarize_all(trip_202006, ~sum(is_missing(.) / nrow(trip_202006)))
summarize_all(trip_202005, ~sum(is_missing(.) / nrow(trip_202005)))
summarize_all(trip_202004, ~sum(is_missing(.) / nrow(trip_202004)))
```

It's clear that lots of missing data come from variables: start_station_name, start_station_id, end_station_name, and end_station_id. Although there are missing values in some variables, the number for individual month is not significant. It will be checked again later after all data has been aggregated.

#### Combining all the datasets

Now I stack the dataframes.

```{r stack_dataframes}
stack_trip <- bind_rows(
  trip_2019q3_3,
  trip_2019q4_3,
  trip_2020q1_2,
  trip_202004_2,
  trip_202005_2,
  trip_202006_2,
  trip_202007_2,
  trip_202008_2,
  trip_202009_2,
  trip_202010_2,
  trip_202011_2,
  trip_202012,
  trip_202101,
  trip_202102,
  trip_202103,
  trip_202104,
  trip_202105,
  trip_202106
)
```

#### Checking missing values in the combined dataset

To fulfill my curiosity, I then check for missing values of the stacked data overall.

```{r check_for_missing_values_3}
summarize_all(stack_trip, ~sum(is_missing(.) / nrow(stack_trip)))
```

There are around 5-6% missing values in station variables and less than 1% in end_lat and end_lng variables. The stakeholder might be interested in knowing these facts. Moreover, the missing values in different variables are expected because of different column number and different variables, which can be deleted to make things easier and those variables are not needed for this analysis according to the business task.

```{r delete_unnecessary_variables}
stack_trip_2 <- stack_trip %>% 
  select(-c(start_lat, start_lng, end_lat, end_lng, birthyear, gender, tripduration))
```

#### Inspecting the structure of the combined data

Then I inspect the newly created dataframe

```{r inspect_dataframe_v2}
colnames(stack_trip_2)
nrow(stack_trip_2)
dim(stack_trip_2)
head(stack_trip_2)
str(stack_trip_2)
summary(stack_trip_2)
```

The business task is concerned with the difference in trends between two membership of bike ride; casual and member. First I check if there are only 2 entries in the member variable.

```{r check_membership_type_1}
member_casual_n <- data.frame(table(stack_trip_2$member_casual))
member_casual_n
```

There are currently 4 types of membership in the stacked table, but there should be only 2 types of membership. Therefore I replace "Subscriber" with "member" and "Customer" with "casual".

```{r replace_memberhip}
stack_trip_3 <- stack_trip_2 %>% 
  mutate(member_casual = recode(member_casual,
                                "Subscriber" = "member",
                                "Customer" = "casual"))
stack_trip_3 <- stack_trip_3 %>% 
  mutate(member_casual = recode(member_casual,
                                "member" = "Member",
                                "casual" = "Casual"))
```

In this case I create a new stacked dataframe. I want to maintain all tables that I processed. Then I check for the membership type again.

```{r check_membership_type_2}
member_casual_n <- data.frame(table(stack_trip_3$member_casual))
member_casual_n
```

Now that it can be confirmed that there are only two entries in member_casual variable, I then continue to fulfill my curiosity regarding the number of stations in the dataset.

```{r check_number_of_stations}
start_station_name_n <- data.frame(table(stack_trip$start_station_name))
end_station_name_n <- data.frame(table(stack_trip$end_station_name))

str(start_station_name_n)
str(end_station_name_n)
```

Apparently there are more than 700 stations in which the bikes are stationed. Now I check whether all trips started and ended in the same day. I use the code from [here](https://www.statmethods.net/input/dates.html).

```{r check_start_end_station_same}
date_start <- as.Date(stack_trip_3$started_at)
date_end <- as.Date(stack_trip_3$ended_at)

day_start <- format(as.Date(date_start))
day_end <- format(as.Date(date_end))

identical(day_start, day_end)
```
Apparently there are some trips that started and ended in different day.

### Analyzing the Data

#### Adding Trip Duration Variable

Enough with my own curiosity, now I add another variable/column in the dataframe and name it trip_length and calculate the trip duration to put there. I use the code from [here](https://stat.ethz.ch/R-manual/R-devel/library/base/html/difftime.html).

```{r add_trip_length}
stack_trip_3$trip_length <- difftime(stack_trip_3$ended_at, stack_trip_3$started_at)
```

After adding the column, I check for the structure of the dataframe again.

```{r check_str_dataframe_3}
str(stack_trip_3)
```


Now that the trip_length column has been added, I need to change the data type into numeric so it can be analyzed properly.

```{r change_data_type_trip_length}
is.factor(stack_trip_3$trip_length)
stack_trip_3$trip_length <- as.numeric(as.character(stack_trip_3$trip_length))
is.numeric(stack_trip_3$trip_length)
```

#### Checking the Duration of the Trips Summary

Then I want to check the general summary of the trip duration.

```{r general_summary_trip_duration}
summary(stack_trip_3$trip_length)
```

#### Organizing the Data Again

Whoops, there are trips with negative trip_length. Moreover, there is also a trip with 9387024 seconds (108 days). I don't know what happened to the trip in the latter case, but for now I will just filter out the negative values. At the same time, I will filter out the trip that started from "HQ QH" since it comes from the guide, that is, filtering out the trips that started in "HQ QR" since it means that the bike is taken out of docks and checked for quality.

```{r}
stack_trip_4 <- stack_trip_3[!(stack_trip_3$start_station_name == "HQ QR" |
                                 stack_trip_3$end_station_name == "HQ QR" |
                                 stack_trip_3$trip_length < 0), ]
```

Then I check again for general summary after the filter.

```{r general_summary_trip_duration_2}
summary(stack_trip_4$trip_length)
```

I want to make sure there is no trip started from "HQ QR" as well.

```{r check_for_HQQR}
start_station_name_n <- data.frame(table(stack_trip_4$start_station_name))
end_station_name_n <- data.frame(table(stack_trip_4$end_station_name))
start_station_name_n
end_station_name_n
```

#### Adding more variables: Year, Month, Day, and Day of the Week

Now I have added additional variables of started_date and ended_date and separate the year, month, day, and day of the week for each variables.
I think we only need the started_date, but I'm also curious about the ended_date.

```{r separate_day_month_year_day_of_the_week}
stack_trip_4$start_date <- as.Date(stack_trip_4$started_at)
stack_trip_4$start_day <- format(as.Date(stack_trip_4$start_date), "%d")
stack_trip_4$start_month <- format(as.Date(stack_trip_4$start_date), "%m")
stack_trip_4$start_year <- format(as.Date(stack_trip_4$start_date), "%Y")
stack_trip_4$start_day_of_week <- format(as.Date(stack_trip_4$start_date), "%A")

stack_trip_4$end_date <- as.Date(stack_trip_4$ended_at)
stack_trip_4$end_day <- format(as.Date(stack_trip_4$end_date), "%d")
stack_trip_4$end_month <- format(as.Date(stack_trip_4$end_date), "%m")
stack_trip_4$end_year <- format(as.Date(stack_trip_4$end_date), "%Y")
stack_trip_4$end_day_of_week <- format(as.Date(stack_trip_4$end_date), "%A")
```

#### Analysis: Members vs Casuals Comparison

Then I compare members and casuals.

```{r compare_members_vs_casuals}
aggregate(stack_trip_4$trip_length ~ stack_trip_4$member_casual, FUN = mean)
aggregate(stack_trip_4$trip_length ~ stack_trip_4$member_casual, FUN = median)
aggregate(stack_trip_4$trip_length ~ stack_trip_4$member_casual, FUN = max)
aggregate(stack_trip_4$trip_length ~ stack_trip_4$member_casual, FUN = min)
```

It seems that on average casuals used the bike more than twice as often as the members. So I check again for the average duration by day of the week for members and casual users.

```{r check_avg_duration_by_day}
aggregate(stack_trip_4$trip_length ~ stack_trip_4$member_casual + stack_trip_4$start_day_of_week, FUN = mean)
```

#### Analysis: Ridership data by Type and Day of the Week

Now that it has come to analysis, I want to analyze the ridership data by type and day of the week first. I also add median metric to let me check whether the distribution of trip duration is skewed.

```{r summary_by_type_and_weekday}
stack_trip_day_summary <- stack_trip_4 %>% 
  mutate(start_weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, start_weekday) %>% 
  summarize(start_number_of_rides = n(), trip_average_duration = mean(trip_length), trip_median_duration = median(trip_length)) %>% 
  arrange(member_casual, start_weekday)
```

Then I visualize the number of rides by type and day of the week.

```{r viz_number_of_rides_by_type_and_day_of_the_week}
ggplot(data = stack_trip_day_summary,
       aes(x = start_weekday,
           y = start_number_of_rides / 1000,
           fill = member_casual)) +
  geom_col(position = "dodge") +
  xlab("Day of the Week") +
  ylab("Number of Rides (Thousands)") +
  labs(title = "The Number of Rides Trend According to Day of The Week",
       subtitle = "The number of rides of casuals are highest on Sundays and Saturdays") +
  scale_fill_discrete(name = "Membership Type")
```
```{r save_plot_01}
ggsave("01_Number_of_rides_trend_day_of_the_week.png",
       width = 22,
       height = 15,
       units = "cm")
```


Then visualizing the average duration by type and day of the week.

```{r viz_avg_dur_by_type_and_day_of_the_week}
ggplot(data = stack_trip_day_summary,
       aes(x = start_weekday,
           y = trip_average_duration / 60,
           fill = member_casual)) +
  geom_col(position = "dodge") +
  xlab("Day of the Week") +
  ylab("Average Duration (Minutes)") +
  labs(title = "The Average Duration of Rides Trend According to Day of The Week",
       subtitle = "The average duration of casuals' rides are more than twice longer than that of members'.") +
  scale_fill_discrete(name = "Membership Type")
```
```{r save_plot_2}
ggsave("02_Average_duration_trend_day_of_the_week.png",
       width = 22,
       height = 15,
       units = "cm")
```


Then also visualizing the median duration by type and day of the week.

```{r viz_median_dur_by_type_and_day_of_the_week}
ggplot(data = stack_trip_day_summary,
       aes(x = start_weekday,
           y = trip_median_duration / 60,
           fill = member_casual)) +
  geom_col(position = "dodge") +
  xlab("Day of the Week") +
  ylab("Median Duration (Minutes)") +
  labs(title = "The Median Duration of Rides Trend According to Day of The Week",
       subtitle = "The median duration of rides are far lower than the average duration.") +
  scale_fill_discrete(name = "Membership Type")
```
```{r save_plot_3}
ggsave("03_Median_duration_trend_day_of_the_week.png",
       width = 22,
       height = 15,
       units = "cm")
```


#### Analysis: Ridership data by Membership Type and Month (Average Trip Duration)

The is a huge difference between the average and median duration. This shows that the distribution of the trip duration is obviously skewed. Now I want to know the difference in trend since the beginning of the COVID-19 pandemic using the code written by "sbha" [here](https://stackoverflow.com/questions/18115550/combine-two-or-more-columns-in-a-dataframe-into-a-new-column-with-a-new-name/40994869).


```{r check_different_before_after_covid}
stack_trip_month_summary <- stack_trip_4 %>% 
  mutate(start_month_year = paste(start_year, start_month, sep = "-")) %>% 
  group_by(start_month_year, member_casual) %>% 
  summarize(number_of_rides_in_a_month = n(),
            trip_average_duration_in_a_month = mean(trip_length),
            trip_median_duration_in_a_month = median(trip_length)) %>% 
  arrange(start_month_year, member_casual)
stack_trip_month_summary_2 <- stack_trip_4 %>% 
  mutate(start_month_year = paste(start_year, start_month, sep = "-")) %>% 
  group_by(start_month_year) %>% 
  summarize(number_of_rides_in_a_month = n(),
            trip_average_duration_in_a_month = mean(trip_length),
            trip_median_duration_in_a_month = median(trip_length)) %>% 
  arrange(start_month_year)
```

Now I visualize the result of the average duration using the code written by Jonathan Chang in [here](https://stackoverflow.com/questions/1330989/rotating-and-spacing-axis-labels-in-ggplot2).

```{r viz_avg_dur_in_a_month}
ggplot(data = stack_trip_month_summary,
       aes(x = start_month_year,
           y = trip_average_duration_in_a_month / 60,
           fill = member_casual)) +
  geom_col(position = "dodge") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  xlab("Year-Month") +
  ylab("Average Duration in a Month (Minutes)") +
  labs(title = "The Average Duration of Trips by Month and Membership Type") +
  scale_fill_discrete(name = "Membership Type") +
  theme(legend.position = c(0.8, 0.8))
```

```{r save_plot_4}
ggsave("04_Average_duration_trend_by_month_membership.png",
       width = 22,
       height = 15,
       units = "cm")
```


```{r viz_avg_dur_in_a_month_sum}
ggplot(data = stack_trip_month_summary_2,
       aes(x = start_month_year,
           y = trip_average_duration_in_a_month / 60)) +
  geom_col(position = "dodge", fill = "blue") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  xlab("Year-Month") +
  ylab("Average Duration in a Month (Minutes)") +
  labs(title = "The Average Duration of Trips by Month",
       subtitle = "The average duration of the trip overall seems to be related to seasons.")
```

```{r save_plot_5}
ggsave("05_Average_duration_trend_by_month.png",
       width = 22,
       height = 15,
       units = "cm")
```

The average duration of the trip overall seems to be related to seasons. In November, December, and January, the trip durations tend to decline. It might be related to winter season. The trip duration is higher in other seasons. The trip duration does not seem to have apparent relationship with pandemic.

#### Analysis: Ridership data by Membership Type and Month (Median Trip Duration)

Now checking the median trip duration by month.

```{r viz_median_dur_in_a_month}
ggplot(data = stack_trip_month_summary,
       aes(x = start_month_year,
           y = trip_median_duration_in_a_month / 60,
           fill = member_casual)) +
  geom_col(position = "dodge") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  xlab("Year-Month") +
  ylab("Median Duration in a Month (Minutes)") +
  labs(title = "The Median Duration of Trips by Month and Membership Type") +
  scale_fill_discrete(name = "Membership Type") +
  theme(legend.position = c(0.85, 0.85))
```

```{r save_plot_6}
ggsave("06_Median_duration_trend_by_month_membership.png",
       width = 22,
       height = 15,
       units = "cm")
```



```{r viz_median_dur_in_a_month_sum}
ggplot(data = stack_trip_month_summary_2,
       aes(x = start_month_year,
           y = trip_median_duration_in_a_month / 60)) +
  geom_col(position = "dodge", fill = "blue") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  xlab("Year-Month") +
  ylab("Median Duration in a Month (Minutes)") +
  labs(title = "The Median Duration of Trips by Month")
```


```{r save_plot_7}
ggsave("07_Median_duration_trend_by_month.png",
       width = 22,
       height = 15,
       units = "cm")
```

There is no apparent difference between mean and median metric for both casuals and members grouped by months. However there are huge differences between mean and median metric for casuals and members grouped by months. This means that there must be outliers in the trip duration, that is, some users may use the bike for too long.

#### Analysis: Ridership data by Membership Type and Month (Number of Trips)

Now I want to check the number of trips in a month.

```{r viz_trip_number_in_a_month}
ggplot(data = stack_trip_month_summary, 
       aes(x = start_month_year,
           y = number_of_rides_in_a_month / 1000,
           fill = member_casual)) +
  geom_col(position = "dodge") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  xlab("Year-Month") +
  ylab("Number of Rides in a Month (Thousand)") +
  labs(title = "The Number of Trips by Month and Membership Type") +
  scale_fill_discrete(name = "Membership Type") +
  theme(legend.position = c(0.75, 0.85))
```
```{r save_plot_8}
ggsave("08_Number_rides_trend_by_month_membership.png",
       width = 22,
       height = 15,
       units = "cm")
```



```{r viz_trip_number_in_a_month_sum}
ggplot(data = stack_trip_month_summary_2,
       aes(x = start_month_year,
           y = number_of_rides_in_a_month / 1000)) +
  geom_col(position = "dodge", fill = "blue") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  xlab("Year-Month") +
  ylab("Number of Rides in a Month (Thousand)") +
  labs(title = "The Number of Trips by Month",
       subtitle = "The number of trips tend to decline during the lockdown policy.")
```
```{r save_plot_9}
ggsave("09_Number_rides_trend_by_month.png",
       width = 22,
       height = 15,
       units = "cm")
```


As expected, the number of trips tend to decline at the beginning of the lockdown policy in the state, as shown in the chart. The number of trips is lower in April 2020 (the beginning of the lockdown) and February 2021 (a subsequent wave of coronavirus in the US).

#### Analysis: Ridership data by Membership Type and Day of the Week (Number of Trips, Average Trip Duration, Median Trip Duration)

Enough curiosity, now back to business. I will focus on the difference in trip duration and trip number in weekdays and weekends.

```{r viz_trip_number_by_day}
ggplot(data = stack_trip_day_summary, 
       aes(x = start_weekday,
           y = start_number_of_rides / 1000,
           fill = member_casual)) +
  geom_col(position = "dodge") +
  xlab("Day of the Week") +
  ylab("Number of Rides (Thousand)") +
  labs(title = "The Number of Rides Trend According to Day of The Week",
       subtitle = "The number of rides of casuals are highest on Sundays and Saturdays") +
  scale_fill_discrete(name = "Membership Type")
```


```{r viz_avg_duration_by_day}
ggplot(data = stack_trip_day_summary,
       aes(x = start_weekday,
           y = trip_average_duration / 60,
           fill = member_casual)) +
  geom_col(position = "dodge") +
  xlab("Day of the Week") +
  ylab("Average Duration (Minutes)") +
  labs(title = "The Average Duration of Rides Trend According to Day of The Week",
       subtitle = "The average duration of casuals' rides are more than twice longer than that of members'.") +
  scale_fill_discrete(name = "Membership Type")
```
#### Analysis: Ridership data by Membership Type, Day of the Week, and Starting Station (Number of Trips, Average Trip Duration, Median Trip Duration)

Now I group the mean duration, median duration, and number of trips by starting station and membership type.

```{r group_by_station_membership}
stack_trip_station_summary <- stack_trip_4 %>% 
  mutate(start_weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, start_weekday, start_station_name) %>% 
  summarize(start_number_of_rides = n(), trip_average_duration = mean(trip_length), trip_median_duration = median(trip_length)) %>% 
  arrange(member_casual, start_weekday, start_station_name)
stack_trip_station_summary_2 <- stack_trip_4 %>% 
  mutate(start_weekday = wday(started_at, label = TRUE)) %>% 
  group_by(start_weekday, start_station_name) %>% 
  summarize(start_number_of_rides = n(), trip_average_duration = mean(trip_length), trip_median_duration = median(trip_length)) %>% 
  arrange(start_weekday, desc(start_number_of_rides))
```

Then I visualize the total number of rides grouped by day of the week and station in a heatmap chart. First of all I convert the long data into short data. Then I also filter out the station that has number of rides below 6000 (just to let me know if there is any insight from the data) in one day and those from unknown station as well. The code is inspired by Giovanni Colitti's code in [here](https://stackoverflow.com/questions/59327101/pivot-wider-does-not-seem-to-work-with-missing-values-how-to-turn-spread-into).

```{r summarizing_and_filtering}
stack_trip_station_summary_2_number_of_rides <- stack_trip_4 %>% 
  mutate(start_weekday = wday(started_at, label = TRUE)) %>% 
  group_by(start_weekday, start_station_name) %>% 
  summarize(start_number_of_rides = n()) %>% 
  ungroup() %>% 
  pivot_wider(names_from = start_weekday,
              values_from = start_number_of_rides,
              names_repair = "minimal") %>% 
  mutate(total_ride = Sun + Mon + Tue + Wed + Thu + Fri + Sat) %>% 
  filter((Sun > 6000 | Mon > 6000 | Tue > 6000 | Wed > 6000 | Thu > 6000 | Fri > 6000 | Sat > 6000) & !(start_station_name == "")) %>% 
  arrange(desc(total_ride))
```

Then I convert the wide data into long data using a code from [here](https://tidyr.tidyverse.org/reference/pivot_longer.html).

```{r convert_wide_to_long}
stack_trip_station_summary_2_number_of_rides_long <- stack_trip_station_summary_2_number_of_rides %>% 
  pivot_longer(!start_station_name,
               names_to = "day_of_the_week",
               values_to = "rides_number")
```

Now I will replace the values in variables day of the week so that the visualization is proper. I don't know the quicker way of doing this, but this is my code.

```{r replace_value_days}
stack_trip_station_summary_2_number_of_rides_long$day_of_the_week[stack_trip_station_summary_2_number_of_rides_long$day_of_the_week == "Mon"] <- "(8) Mon"
stack_trip_station_summary_2_number_of_rides_long$day_of_the_week[stack_trip_station_summary_2_number_of_rides_long$day_of_the_week == "Tue"] <- "(7) Tues"
stack_trip_station_summary_2_number_of_rides_long$day_of_the_week[stack_trip_station_summary_2_number_of_rides_long$day_of_the_week == "Wed"] <- "(6) Wed"
stack_trip_station_summary_2_number_of_rides_long$day_of_the_week[stack_trip_station_summary_2_number_of_rides_long$day_of_the_week == "Thu"] <- "(5) Thu"
stack_trip_station_summary_2_number_of_rides_long$day_of_the_week[stack_trip_station_summary_2_number_of_rides_long$day_of_the_week == "Fri"] <- "(4) Fri"
stack_trip_station_summary_2_number_of_rides_long$day_of_the_week[stack_trip_station_summary_2_number_of_rides_long$day_of_the_week == "Sat"] <- "(3) Sat"
stack_trip_station_summary_2_number_of_rides_long$day_of_the_week[stack_trip_station_summary_2_number_of_rides_long$day_of_the_week == "Sun"] <- "(2) Sun"
stack_trip_station_summary_2_number_of_rides_long$day_of_the_week[stack_trip_station_summary_2_number_of_rides_long$day_of_the_week == "total_ride"] <- "(1) 1-Week Total"
```

Finally I can plot into a heatmap chart.

```{r plot_heatmap, fig.width = 12, fig.height = 4.5}
ggplot(stack_trip_station_summary_2_number_of_rides_long,
       aes(y = day_of_the_week,
           x = start_station_name,
           fill = rides_number)) +
  geom_tile() +
  scale_x_discrete(position = "bottom") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  scale_fill_gradient(name = "Number of Rides",
                      low = "#FFFFFF",
                      high = "#012345") +
  xlab("Station") +
  ylab("Day of the Week") +
  labs(title = "The Number of Rides in some Stations with most Bike Uses",
       subtitle = "The number of rides are highest in Streeter Dr & Grand Ave.")
```
```{r save_plot_10}
ggsave("10_Number_rides_station_most_uses.png",
       width = 28,
       height = 12,
       units = "cm")
```

The stakeholder can use this heatmap chart to prioritize where to put physical ads in the stations with darker colors, or to give promotion via mobile apps prioritizing the casuals in these stations. 

#### Analysis: Ridership data by Membership Type, Trip Duration, and Number of Trips

Then I try creating histogram from the grouped data using the code [here](https://stackoverflow.com/questions/34774120/set-number-of-bins-for-histogram-directly-in-ggplot). I remove the trip duration more than 4500 since it might not be material in this analysis.

```{r renaming_day}
stack_trip_5 <- stack_trip_4
stack_trip_5$start_day_of_week[stack_trip_5$start_day_of_week == "Monday"] <- "(1) Monday"
stack_trip_5$start_day_of_week[stack_trip_5$start_day_of_week == "Tuesday"] <- "(2) Tuesday"
stack_trip_5$start_day_of_week[stack_trip_5$start_day_of_week == "Wednesday"] <- "(3) Wednesday"
stack_trip_5$start_day_of_week[stack_trip_5$start_day_of_week == "Thursday"] <- "(4) Thursday"
stack_trip_5$start_day_of_week[stack_trip_5$start_day_of_week == "Friday"] <- "(5) Friday"
stack_trip_5$start_day_of_week[stack_trip_5$start_day_of_week == "Saturday"] <- "(6) Saturday"
stack_trip_5$start_day_of_week[stack_trip_5$start_day_of_week == "Sunday"] <- "(7) Sunday"
```



```{r viz_histogram, fig.width = 13, fig.height = 4.5}
ggplot(data = stack_trip_5, aes(x = trip_length / 60)) +
  geom_histogram(aes(y = ..count.. / 1000), bins = 120, fill = "white", color = "purple") + 
  xlim(0, 75) +
  theme(axis.text.x = element_text(angle = 0, vjust = 0, hjust = 0.5)) +
  facet_grid(member_casual ~ start_day_of_week) +
  xlab("Trips Duration (minutes)") +
  ylab("Number of Trips (Thousand)") +
  labs(title = "The Distribution of Trips Duration by Day of the Week",
       subtitle = "The distribution of trip duration is positively skewed, with casuals having more positively skewed distribution of trip duration.")
```
```{r save_plot_11}
ggsave("11_Distribution_trip_duration.png",
       width = 28,
       height = 12,
       units = "cm")
```


## Step 5: SHARE

### Observations

From the visualizations above, it can be observed that:

(1) The number of trips done by casuals tend to lower on weekdays and higher on weekends. This might suggest that members paid annual membership because they use the bike for work.
(2) The number of trips done by casuals on weekdays are around half of those done by members. This might suggest that a proportion of casuals don't really need the bike for work on weekdays. That's probably why they prefer casual membership.
(3) The number of trips done by casuals on weekdays are almost the same as those done by members on weekends. This might suggest that casuals use bike for recreational purpose over trip to work.
(4) The average trip duration by casuals by day are around three times as much as those done by members.
(5) Saturday and Sunday are the most popular day for bike riding for members since the average trip duration tend to get higher on these two days.
(6) On the other hand, Saturday is the most popular day for bike riding for casuals since the average trip duration is peaked on Saturday.
(7) From the histogram, it's clear that the majority of members only use the bike for less than 20 minutes. Meanwhile, the histogram of trip length for casuals have significantly fatter tail, that is, positively skewed.

### Recommendations

Considering the observations above, my recommendations to the stakeholders are as follows:

(1) If the stakeholders are doing ads in person, it is better doing it on weekends and outside winter seasons since the trip number from casuals on weekends and outside winter seasons are almost as high as those of members.
(2) If the stakeholders want to get as much casuals to convert into members as possible, they might consider offering membership of bike use on weekends only with different (slightly lower) pricing from regular annual membership.
(3) If the stakeholders want to get as much casuals to convert into members as possible, they might also consider limit the duration of bike use for single-ride pass, say, for the first 30 minutes (1800 seconds), and charging additional fee for trip more than 30 minutes, while not limiting the duration for members. This should push the casuals to consider full-day passes, since the average trip duration of casuals are around 2500 seconds (42 minutes). To convert full-day passes further into annual membership, the stakeholder might want to consider different (higher) pricing on full-day passes on weekends.
(4) Although the task only requires me to provide 3 recommendation, if possible I would like to add one recommendation regarding the use of digital data. To understand the behaviors of the riders, the stakeholders might want to require the riders to install a mobile phone app by which Cyclistic can notify the users about any promotion or advertisements. The stakeholders might also want to install GPS trackers on the bikes to understand the riders better. I don't know whether the company has implemented this, but if not it might be useful to consider if it's not a violation of privacy. Also, the stakeholders might want to conduct marketing using social media, such as free-ride for users who post winning photo (uploaded in the usersâ€™ social media account) taken in various spots in the city. This will let the stakeholders identify which spots are better for marketing purpose.

### Personal Takeaways

My personal takeaways from this project:

It would be more interesting if I have the more completed data in order to:

* Distinguish single-ride passes from full-day passes in the datasets
* Observe how much the rider had to pay for every ride in the past into the datasets
* Add the riding data geolocation to understand the users' behaviors better.

#### I would gladly accept any feedback or suggestions. I am quite a beginner in R, so any feedback to make the codes better is highly appreciated.